{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/entities.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tokens.yml', 'r') as f:\n",
    "    tokens = yaml.safe_load(f)\n",
    "    \n",
    "token_to_col = {}\n",
    "for col in tokens.keys():\n",
    "    token = tokens[col]['start']\n",
    "    token_to_col[token] = col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank_dict(tokens=tokens):\n",
    "    d = {}\n",
    "    for col in list(tokens.keys()):\n",
    "        d[col] = None\n",
    "    return d\n",
    "\n",
    "def split_by_token(line, token_to_col=token_to_col):\n",
    "    tokens_to_split = list(token_to_col.keys())\n",
    "    pattern = '(' + '|'.join(re.escape(token) for token in tokens_to_split) + ')'\n",
    "    \n",
    "    splits = re.split(pattern, line)\n",
    "    # Filter out empty strings and trim kept strings\n",
    "    splits = [part.strip() for part in splits if part]\n",
    "    return splits\n",
    "\n",
    "def split_to_dict(split, token_to_col=token_to_col, dict_split=None):\n",
    "    if dict_split is None:\n",
    "        dict_split = blank_dict()\n",
    "    for i in range(0, len(split), 2):\n",
    "        token = split[i]\n",
    "        element = split[i+1]\n",
    "        column = token_to_col[token]\n",
    "        dict_split[column] = element\n",
    "    return dict_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [00:00<00:00, 3143.14it/s]\n"
     ]
    }
   ],
   "source": [
    "df_dict = {}\n",
    "counter = 0\n",
    "for key in tqdm(data.keys()): \n",
    "    for line in data[key].split('\\n'):\n",
    "        try:\n",
    "            split = split_by_token(line)\n",
    "            split_dict = split_to_dict(split)\n",
    "            df_dict[counter] = split_dict\n",
    "                    \n",
    "            counter += 1\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame().from_dict(df_dict, orient='index').fillna(value=np.nan)\n",
    "\n",
    "indices_to_remove = []\n",
    "for i in range(len(df)):\n",
    "    if np.all(df.iloc[i].isna()):\n",
    "        indices_to_remove.append(i)\n",
    "\n",
    "df = df.loc[~df.index.isin(indices_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['surname_household'])\n",
    "y = df['surname_household'].apply(\n",
    "                                lambda x: 0 if pd.isna(x) else 1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>civil_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>employer</th>\n",
       "      <th>firstname</th>\n",
       "      <th>link</th>\n",
       "      <th>lob</th>\n",
       "      <th>maiden_name</th>\n",
       "      <th>nationality</th>\n",
       "      <th>observation</th>\n",
       "      <th>occupation</th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Garçon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cyrille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>française</td>\n",
       "      <td>NaN</td>\n",
       "      <td>menuisier</td>\n",
       "      <td>Breton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Garçon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auguste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Piémontaise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vitrier</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Garçon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Piémontaise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vitrier</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Homme marié</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexandre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>française</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prop re</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zélie</td>\n",
       "      <td>sa fe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>française</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prop re</td>\n",
       "      <td>Vignat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25433</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marie</td>\n",
       "      <td>chef</td>\n",
       "      <td>Pailharès</td>\n",
       "      <td>NaN</td>\n",
       "      <td>idem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25434</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cara</td>\n",
       "      <td>Marie</td>\n",
       "      <td>chef</td>\n",
       "      <td>St Naz en Royans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>idem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ouv chaus res</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25435</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baretto</td>\n",
       "      <td>Nello</td>\n",
       "      <td>chef</td>\n",
       "      <td>Castel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>italienne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>manoeuvre</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25436</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Annunziata</td>\n",
       "      <td>épouse</td>\n",
       "      <td>idem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>idem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berni-Laureti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25437</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primo</td>\n",
       "      <td>fils</td>\n",
       "      <td>idem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>idem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25074 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age birth_date civil_status education_level employer   firstname  \\\n",
       "0       25        NaN       Garçon             NaN      NaN     Cyrille   \n",
       "1       30        NaN       Garçon             NaN      NaN     Auguste   \n",
       "2       24        NaN       Garçon             NaN      NaN      Pierre   \n",
       "3       48        NaN  Homme marié             NaN      NaN   Alexandre   \n",
       "4       30        NaN          NaN             NaN      NaN       Zélie   \n",
       "...    ...        ...          ...             ...      ...         ...   \n",
       "25433  NaN       1869          NaN             NaN      NaN       Marie   \n",
       "25434  NaN       1863          NaN             NaN     Cara       Marie   \n",
       "25435  NaN       1886          NaN             NaN  Baretto       Nello   \n",
       "25436  NaN       1887          NaN             NaN      NaN  Annunziata   \n",
       "25437  NaN       1914          NaN             NaN      NaN       Primo   \n",
       "\n",
       "         link               lob maiden_name  nationality observation  \\\n",
       "0         NaN               NaN         NaN    française         NaN   \n",
       "1         NaN               NaN         NaN  Piémontaise         NaN   \n",
       "2         NaN               NaN         NaN  Piémontaise         NaN   \n",
       "3         NaN               NaN         NaN    française         NaN   \n",
       "4       sa fe               NaN         NaN    française         NaN   \n",
       "...       ...               ...         ...          ...         ...   \n",
       "25433    chef         Pailharès         NaN         idem         NaN   \n",
       "25434    chef  St Naz en Royans         NaN         idem         NaN   \n",
       "25435    chef            Castel         NaN    italienne         NaN   \n",
       "25436  épouse              idem         NaN         idem         NaN   \n",
       "25437    fils              idem         NaN         idem         NaN   \n",
       "\n",
       "          occupation        surname  \n",
       "0          menuisier         Breton  \n",
       "1            vitrier            NaN  \n",
       "2            vitrier            NaN  \n",
       "3            prop re            NaN  \n",
       "4            prop re         Vignat  \n",
       "...              ...            ...  \n",
       "25433            NaN            NaN  \n",
       "25434  ouv chaus res            NaN  \n",
       "25435      manoeuvre            NaN  \n",
       "25436            NaN  Berni-Laureti  \n",
       "25437            NaN          Berni  \n",
       "\n",
       "[25074 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "X_encoded = enc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc, X_test_enc, y_train_enc, y_test_enc = train_test_split(X_encoded, y, test_size=0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [1e-1, 1e-2, 1e-3],\n",
    "    \"max_leaf_nodes\": [15, 31, 100],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [10, 20, 50],\n",
    "    \"l2_regularization\": [0.0, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "model = HistGradientBoostingClassifier(max_iter=10_000, early_stopping=True, class_weight='balanced', validation_fraction=0.2)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1, verbose=0)\n",
    "\n",
    "grid_search.fit(X_train_enc, y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'l2_regularization': 0.1, 'learning_rate': 0.1, 'max_depth': None, 'max_leaf_nodes': 31, 'min_samples_leaf': 10}\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters found\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.999\n",
      "Test accuracy: 0.997\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {clf.score(X_train_enc, y_train_enc):.3f}\")\n",
    "print(f\"Test accuracy: {clf.score(X_test_enc, y_test_enc):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CE loss = 0.0036\n",
      "Test CE loss = 0.0101\n"
     ]
    }
   ],
   "source": [
    "print(f'Train CE loss = {log_loss(y_train_enc, clf.predict_proba(X_train_enc)):.4f}')\n",
    "print(f'Test CE loss = {log_loss(y_test_enc, clf.predict_proba(X_test_enc)):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove surname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a direct inverse correlation between the presence of the surname and being a household leader, in the sense that a household leader has a household surname given but has no surname, and vice versa for non household leaders. Hence, it might be to easy for the model as it only has to check whether there is a surname or not to predict the truth. <br>\n",
    "Hence, we remove this column of information from the training data to see if the model is still able to have great results with the remaining information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "X_encoded_no_surname = enc.fit_transform(X.drop(columns=['surname']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc_no_surname, X_test_enc_no_surname, y_train_enc_no_surname, y_test_enc_no_surname = train_test_split(X_encoded_no_surname, y, test_size=0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = HistGradientBoostingClassifier(max_iter=10_000, early_stopping=True, class_weight='balanced', validation_fraction=0.2)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1, verbose=0)\n",
    "\n",
    "grid_search.fit(X_train_enc_no_surname, y_train_enc_no_surname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters while not using surname: {'l2_regularization': 0.0, 'learning_rate': 0.1, 'max_depth': None, 'max_leaf_nodes': 100, 'min_samples_leaf': 20}\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters found\n",
    "print(\"Best parameters while not using surname:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "clf_no_surname = grid_search.best_estimator_\n",
    "clf_no_surname.fit(X_train_enc_no_surname, y_train_enc_no_surname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy no surname: 0.941\n",
      "Test accuracy no surname: 0.922\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy no surname: {clf_no_surname.score(X_train_enc_no_surname, y_train_enc_no_surname):.3f}\")\n",
    "print(f\"Test accuracy no surname: {clf_no_surname.score(X_test_enc_no_surname, y_test_enc_no_surname):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CE loss no surname = 0.1544\n",
      "Test CE loss no surname = 0.2182\n"
     ]
    }
   ],
   "source": [
    "print(f'Train CE loss no surname = {log_loss(y_train_enc_no_surname, clf_no_surname.predict_proba(X_train_enc_no_surname)):.4f}')\n",
    "print(f'Test CE loss no surname = {log_loss(y_test_enc_no_surname, clf_no_surname.predict_proba(X_test_enc_no_surname)):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_str = np.array([' '.join([str(x) for x in X.iloc[i].dropna(inplace=False).values]) for i in range(len(X))], dtype=str)\n",
    "X_str_train, X_str_test, y_str_train, y_str_test = train_test_split(X_str, y, test_size=0.25, stratify=y)\n",
    "X_str_val, X_str_test, y_str_val, y_str_test = train_test_split(X_str_test, y_str_test, test_size=0.4, stratify=y_str_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-french-europeana-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Step 1: Load pre-trained French language model and tokenizer\n",
    "model_name = \"dbmdz/bert-base-french-europeana-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Assuming binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Tokenize text data\n",
    "# Tokenize input text\n",
    "train_inputs = tokenizer(list(X_str_train), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "val_inputs = tokenizer(list(X_str_val), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_inputs = tokenizer(list(X_str_test), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Convert labels to tensor\n",
    "train_labels = torch.tensor(list(y_str_train))\n",
    "val_labels = torch.tensor(list(y_str_val))\n",
    "test_labels = torch.tensor(list(y_str_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare DataLoader for training and validation sets\n",
    "def to_loader(inputs, labels, batch_size=32, shuffle=True):\n",
    "    dataset = TensorDataset(inputs[\"input_ids\"], inputs[\"attention_mask\"], labels)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return dataset, loader\n",
    "\n",
    "train_dataset, train_loader = to_loader(train_inputs, train_labels, shuffle=True)\n",
    "val_dataset, val_loader = to_loader(val_inputs, val_labels, shuffle=False)\n",
    "test_dataset, test_loader = to_loader(test_inputs, test_labels, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.11/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Fine-tune the pre-trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=\"Epoch {}\".format(epoch)):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"Average training loss:\", avg_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the fine-tuned model on the validation set\n",
    "model.eval()\n",
    "val_accuracy = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        val_accuracy += torch.sum(preds == labels).item()\n",
    "\n",
    "val_accuracy /= len(val_dataset)\n",
    "print(\"Validation Accuracy:\", val_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
